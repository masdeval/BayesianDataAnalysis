# 	      A95 : female : single
# Creating a specific feature for sex
df[df$Personal_status == 'A91' |  df$Personal_status == 'A94' | df$Personal_status == 'A93' ,'Sex'] = 'M'
df[df$Personal_status == 'A92' |  df$Personal_status == 'A95' , 'Sex'] = 'F'
# Adding meaningful descriptions for Personal_status
df[df$Personal_status == 'A91' | df$Personal_status == 'A92', 'Marital_status'] = 'divorced'
df[df$Personal_status == 'A93' , 'Marital_status'] = 'single'
df[df$Personal_status == 'A94' , 'Marital_status'] = 'married'
df$Personal_status = NULL
df$sex = as.factor(df$Sex)
df$Marital_status = as.factor(df$Marital_status)
#str(df)
#library(dplyr)
#group_by(df[df$Credit_default==1,],Purpose)  %>% summarise(n())
#group_by(df,Personal_status)  %>% summarise(n())
library(caret)
# Creating a balanced split for train/test sets : 30% test 70% train
# This will be usefull to compare the logistic model with others
data_part <- createDataPartition(y = df$Credit_default, p = 0.7, list = F)
X_train = df[data_part,]
#y_train = df[data_part,c('Credit_default')]
X_test = df[-data_part,!(colnames(df) %in% 'Credit_default')]
y_test = df[-data_part,c('Credit_default')]
# Checking balance
table(y_test)
table(X_train$Credit_default)
# Fiting a logistic model
glm.fit = glm(Credit_default~.,data = df, family = binomial)
summary(glm.fit)
# Predicting
glm.pred = predict.glm(glm.fit, newdata = X_test, type = "response")
# Calculating accuracy
glm.pred.class = ifelse(glm.pred > 0.5, 1, 0)
mean(y_test == glm.pred.class)
library(pROC)
plot(roc(y_test, glm.pred, direction="<"),col="red", lwd=3, main="")
confusionMatrix(data=factor(glm.pred.class, levels = c(0,1)), reference=factor(y_test, levels = c(0,1)))
measurePrecisionRecall(glm.pred.class, y_test)
knitr::opts_chunk$set(echo = TRUE)
measurePrecisionRecall <- function(predict, actual_labels){
precision <- sum(predict & actual_labels) / sum(predict)
recall <- sum(predict & actual_labels) / sum(actual_labels)
fmeasure <- 2 * precision * recall / (precision + recall)
cat('\nPrecision:  ')
cat(round(precision,2))
cat('\n')
cat('Recall (sensitivity):     ')
cat(round(recall,2))
cat('\n')
cat('F-score:  ')
cat(round(fmeasure,2))
cat('\n')
}
# Cheking missing values
sort(colSums(is.na(df)),decreasing = T)
df = data.frame(read.csv('GermanData.csv'))
colnames(df) <- c("Status_Checking", "Duration", "Credit_history", "Purpose", "Credit_amount",
"Saving","Empolyment_duration", "Installment_rate", "Personal_status",
"Otherdebtors", "Residence_Year", "Property", "Age", "Other_installment_plan",
"Housing", "Exisiting_credits", "Job", "Liable_People", "Telephone",
"Foreign_worker", "Credit_default")
df[df$Credit_default==1,'Credit_default'] = 0  # no default
df[df$Credit_default==2,'Credit_default'] = 1  # default
# Handling attibute 9
# Attribute 9:  (qualitative)
# 	      Personal status and sex
# 	      A91 : male   : divorced/separated
# 	      A92 : female : divorced/separated/married
#         A93 : male   : single
# 	      A94 : male   : married/widowed
# 	      A95 : female : single
# Creating a specific feature for sex
df[df$Personal_status == 'A91' |  df$Personal_status == 'A94' | df$Personal_status == 'A93' ,'Sex'] = 'M'
df[df$Personal_status == 'A92' |  df$Personal_status == 'A95' , 'Sex'] = 'F'
# Adding meaningful descriptions for Personal_status
df[df$Personal_status == 'A91' | df$Personal_status == 'A92', 'Marital_status'] = 'divorced'
df[df$Personal_status == 'A93' , 'Marital_status'] = 'single'
df[df$Personal_status == 'A94' , 'Marital_status'] = 'married'
df$Personal_status = NULL
df$sex = as.factor(df$Sex)
df$Marital_status = as.factor(df$Marital_status)
#str(df)
#library(dplyr)
#group_by(df[df$Credit_default==1,],Purpose)  %>% summarise(n())
#group_by(df,Personal_status)  %>% summarise(n())
knitr::opts_chunk$set(echo = TRUE)
measurePrecisionRecall <- function(predict, actual_labels){
precision <- sum(predict & actual_labels) / sum(predict)
recall <- sum(predict & actual_labels) / sum(actual_labels)
fmeasure <- 2 * precision * recall / (precision + recall)
cat('\nPrecision:  ')
cat(round(precision,2))
cat('\n')
cat('Recall (sensitivity):     ')
cat(round(recall,2))
cat('\n')
cat('F-score:  ')
cat(round(fmeasure,2))
cat('\n')
}
# Cheking missing values
sort(colSums(is.na(df)),decreasing = T)
df = data.frame(read.csv('GermanData.csv'))
colnames(df) <- c("Status_Checking", "Duration", "Credit_history", "Purpose", "Credit_amount",
"Saving","Empolyment_duration", "Installment_rate", "Personal_status",
"Otherdebtors", "Residence_Year", "Property", "Age", "Other_installment_plan",
"Housing", "Exisiting_credits", "Job", "Liable_People", "Telephone",
"Foreign_worker", "Credit_default")
df[df$Credit_default==1,'Credit_default'] = 0  # no default
df[df$Credit_default==2,'Credit_default'] = 1  # default
# Feature engineering
# Handling attibute 9
# Attribute 9:  (qualitative)
# 	      Personal status and sex
# 	      A91 : male   : divorced/separated
# 	      A92 : female : divorced/separated/married
#         A93 : male   : single
# 	      A94 : male   : married/widowed
# 	      A95 : female : single
# Creating a specific feature for sex
df[df$Personal_status == 'A91' |  df$Personal_status == 'A94' | df$Personal_status == 'A93' ,'Sex'] = 'M'
df[df$Personal_status == 'A92' |  df$Personal_status == 'A95' , 'Sex'] = 'F'
# Adding meaningful descriptions for Personal_status
df[df$Personal_status == 'A91' | df$Personal_status == 'A92', 'Marital_status'] = 'divorced'
df[df$Personal_status == 'A93' , 'Marital_status'] = 'single'
df[df$Personal_status == 'A94' , 'Marital_status'] = 'married'
df$Personal_status = NULL
df$sex = as.factor(df$Sex)
df$Marital_status = as.factor(df$Marital_status)
#str(df)
#library(dplyr)
#group_by(df[df$Credit_default==1,],Purpose)  %>% summarise(n())
#group_by(df,Personal_status)  %>% summarise(n())
library(caret)
# Creating a balanced split for train/test sets : 30% test 70% train
# This will be usefull to compare the logistic model with others
data_part <- createDataPartition(y = df$Credit_default, p = 0.7, list = F)
X_train = df[data_part,]
#y_train = df[data_part,c('Credit_default')]
X_test = df[-data_part,!(colnames(df) %in% 'Credit_default')]
y_test = df[-data_part,c('Credit_default')]
# Checking balance
table(y_test)
table(X_train$Credit_default)
# Fiting a logistic model
glm.fit = glm(X_train~.,data = df, family = binomial)
class(X_train)
library(caret)
# Creating a balanced split for train/test sets : 30% test 70% train
# This will be usefull to compare the logistic model with others
data_part <- createDataPartition(y = df$Credit_default, p = 0.7, list = F)
X_train = df[data_part,]
#y_train = df[data_part,c('Credit_default')]
X_test = df[-data_part,!(colnames(df) %in% 'Credit_default')]
y_test = df[-data_part,c('Credit_default')]
# Checking balance
table(y_test)
table(X_train$Credit_default)
# Fiting a logistic model
glm.fit = glm(Credit_default~., data = X_train, family = binomial)
summary(glm.fit)
# Predicting
glm.pred = predict.glm(glm.fit, newdata = X_test, type = "response")
# Calculating accuracy
glm.pred.class = ifelse(glm.pred > 0.5, 1, 0)
mean(y_test == glm.pred.class)
library(pROC)
plot(roc(y_test, glm.pred, direction="<"),col="red", lwd=3, main="")
confusionMatrix(data=factor(glm.pred.class, levels = c(0,1)), reference=factor(y_test, levels = c(0,1)))
measurePrecisionRecall(glm.pred.class, y_test)
View(df)
knitr::opts_chunk$set(echo = TRUE)
measurePrecisionRecall <- function(predict, actual_labels){
precision <- sum(predict & actual_labels) / sum(predict)
recall <- sum(predict & actual_labels) / sum(actual_labels)
fmeasure <- 2 * precision * recall / (precision + recall)
cat('\nPrecision:  ')
cat(round(precision,2))
cat('\n')
cat('Recall (sensitivity):     ')
cat(round(recall,2))
cat('\n')
cat('F-score:  ')
cat(round(fmeasure,2))
cat('\n')
}
# Cheking missing values
sort(colSums(is.na(df)),decreasing = T)
df = data.frame(read.csv('GermanData.csv'))
colnames(df) <- c("Status_Checking", "Duration", "Credit_history", "Purpose", "Credit_amount",
"Saving","Empolyment_duration", "Installment_rate", "Personal_status",
"Otherdebtors", "Residence_Year", "Property", "Age", "Other_installment_plan",
"Housing", "Exisiting_credits", "Job", "Liable_People", "Telephone",
"Foreign_worker", "Credit_default")
df[df$Credit_default==1,'Credit_default'] = 0  # no default
df[df$Credit_default==2,'Credit_default'] = 1  # default
# Feature engineering
# Handling attibute 9
# Attribute 9:  (qualitative)
# 	      Personal status and sex
# 	      A91 : male   : divorced/separated
# 	      A92 : female : divorced/separated/married
#         A93 : male   : single
# 	      A94 : male   : married/widowed
# 	      A95 : female : single
# Creating a specific feature for sex
df[df$Personal_status == 'A91' |  df$Personal_status == 'A94' | df$Personal_status == 'A93' ,'Sex'] = 'M'
df[df$Personal_status == 'A92' |  df$Personal_status == 'A95' , 'Sex'] = 'F'
# Adding meaningful descriptions for Personal_status
df[df$Personal_status == 'A91' | df$Personal_status == 'A92', 'Marital_status'] = 'divorced'
df[df$Personal_status == 'A93' , 'Marital_status'] = 'single'
df[df$Personal_status == 'A94' , 'Marital_status'] = 'married'
df$Personal_status = NULL
df$Sex = as.factor(df$Sex)
df$Marital_status = as.factor(df$Marital_status)
#str(df)
#library(dplyr)
#group_by(df[df$Credit_default==1,],Purpose)  %>% summarise(n())
#group_by(df,Personal_status)  %>% summarise(n())
library(caret)
# Creating a balanced split for train/test sets : 30% test 70% train
# This will be usefull to compare the logistic model with others
data_part <- createDataPartition(y = df$Credit_default, p = 0.7, list = F)
X_train = df[data_part,]
#y_train = df[data_part,c('Credit_default')]
X_test = df[-data_part,!(colnames(df) %in% 'Credit_default')]
y_test = df[-data_part,c('Credit_default')]
# Checking balance
table(y_test)
table(X_train$Credit_default)
# Fiting a logistic model
glm.fit = glm(Credit_default~., data = X_train, family = binomial)
summary(glm.fit)
# Predicting
glm.pred = predict.glm(glm.fit, newdata = X_test, type = "response")
# Calculating accuracy
glm.pred.class = ifelse(glm.pred > 0.5, 1, 0)
mean(y_test == glm.pred.class)
library(pROC)
plot(roc(y_test, glm.pred, direction="<"),col="red", lwd=3, main="")
confusionMatrix(data=factor(glm.pred.class, levels = c(0,1)), reference=factor(y_test, levels = c(0,1)))
measurePrecisionRecall(glm.pred.class, y_test)
str(df)
knitr::opts_chunk$set(echo = TRUE)
measurePrecisionRecall <- function(predict, actual_labels){
precision <- sum(predict & actual_labels) / sum(predict)
recall <- sum(predict & actual_labels) / sum(actual_labels)
fmeasure <- 2 * precision * recall / (precision + recall)
cat('\nPrecision:  ')
cat(round(precision,2))
cat('\n')
cat('Recall (sensitivity):     ')
cat(round(recall,2))
cat('\n')
cat('F-score:  ')
cat(round(fmeasure,2))
cat('\n')
}
# Cheking missing values
sort(colSums(is.na(df)),decreasing = T)
df = data.frame(read.csv('GermanData.csv'))
colnames(df) <- c("Status_Checking", "Duration", "Credit_history", "Purpose", "Credit_amount",
"Saving","Empolyment_duration", "Installment_rate", "Personal_status",
"Otherdebtors", "Residence_Year", "Property", "Age", "Other_installment_plan",
"Housing", "Exisiting_credits", "Job", "Liable_People", "Telephone",
"Foreign_worker", "Credit_default")
df[df$Credit_default==1,'Credit_default'] = 0  # no default
df[df$Credit_default==2,'Credit_default'] = 1  # default
# Feature engineering
# Handling attibute 9
# Attribute 9:  (qualitative)
# 	      Personal status and sex
# 	      A91 : male   : divorced/separated
# 	      A92 : female : divorced/separated/married
#         A93 : male   : single
# 	      A94 : male   : married/widowed
# 	      A95 : female : single
# Creating a specific feature for sex
df[df$Personal_status == 'A91' |  df$Personal_status == 'A94' | df$Personal_status == 'A93' ,'Sex'] = 'M'
df[df$Personal_status == 'A92' |  df$Personal_status == 'A95' , 'Sex'] = 'F'
# Adding meaningful descriptions for Personal_status
df[df$Personal_status == 'A91' | df$Personal_status == 'A92', 'Marital_status'] = 'divorced'
df[df$Personal_status == 'A93' , 'Marital_status'] = 'single'
df[df$Personal_status == 'A94' , 'Marital_status'] = 'married'
df$Personal_status = NULL
df$Sex = as.factor(df$Sex)
df$Marital_status = as.factor(df$Marital_status)
str(df)
#library(dplyr)
#group_by(df[df$Credit_default==1,],Purpose)  %>% summarise(n())
#group_by(df,Personal_status)  %>% summarise(n())
library(caret)
# Creating a balanced split for train/test sets : 30% test 70% train
# This will be usefull to compare the logistic model with others
data_part <- createDataPartition(y = df$Credit_default, p = 0.7, list = F)
X_train = df[data_part,]
#y_train = df[data_part,c('Credit_default')]
X_test = df[-data_part,!(colnames(df) %in% 'Credit_default')]
y_test = df[-data_part,c('Credit_default')]
# Checking balance
table(y_test)
table(X_train$Credit_default)
# Fiting a logistic model
glm.fit = glm(Credit_default~., data = X_train, family = binomial)
summary(glm.fit)
# Predicting
glm.pred = predict.glm(glm.fit, newdata = X_test, type = "response")
# Calculating accuracy
glm.pred.class = ifelse(glm.pred > 0.5, 1, 0)
mean(y_test == glm.pred.class)
library(pROC)
plot(roc(y_test, glm.pred, direction="<"),col="red", lwd=3, main="")
confusionMatrix(data=factor(glm.pred.class, levels = c(0,1)), reference=factor(y_test, levels = c(0,1)))
measurePrecisionRecall(glm.pred.class, y_test)
confusionMatrix(data=factor(glm.pred.class, levels = c(0,1)), reference=factor(y_test, levels = c(0,1)))
library(caret)
set.seed(7)
# Creating a balanced split for train/test sets : 30% test 70% train
# This will be usefull to compare the logistic model with others
data_part <- createDataPartition(y = df$Credit_default, p = 0.7, list = F)
X_train = df[data_part,]
#y_train = df[data_part,c('Credit_default')]
X_test = df[-data_part,!(colnames(df) %in% 'Credit_default')]
y_test = df[-data_part,c('Credit_default')]
# Checking balance
table(y_test)
table(X_train$Credit_default)
# Fiting a logistic model
glm.fit = glm(Credit_default~., data = X_train, family = binomial)
summary(glm.fit)
# Predicting
glm.pred = predict.glm(glm.fit, newdata = X_test, type = "response")
# Calculating accuracy
glm.pred.class = ifelse(glm.pred > 0.5, 1, 0)
mean(y_test == glm.pred.class)
library(pROC)
plot(roc(y_test, glm.pred, direction="<"),col="red", lwd=3, main="")
confusionMatrix(data=factor(glm.pred.class, levels = c(0,1)), reference=factor(y_test, levels = c(0,1)))
measurePrecisionRecall(glm.pred.class, y_test)
mean(y_test == glm.pred.class)
confusionMatrix(data=factor(glm.pred.class, levels = c(0,1)), reference=factor(y_test, levels = c(0,1)))
confusionMatrix(data=factor(glm.pred.class, levels = c(0,1)), reference=factor(y_test, levels = c(0,1)))
measurePrecisionRecall(glm.pred.class, y_test)
confusionMatrix(data=factor(glm.pred.class, levels = c(1,0)), reference=factor(y_test, levels = c(1,0)))
confusionMatrix(data=factor(glm.pred.class, levels = c(1,0)), reference=factor(y_test, levels = c(1,0)))
measurePrecisionRecall(glm.pred.class, y_test)
confusionMatrix(data=factor(glm.pred.class, levels = c(1,0)), reference=factor(y_test, levels = c(1,0)),prevalence=.3)
confusionMatrix(data=factor(glm.pred.class, levels = c(1,0)), reference=factor(y_test, levels = c(1,0)))
measurePrecisionRecall(glm.pred.class, y_test)
source('~/GWU/Bayesian Methods Data Analysis/project/credit_loan_classification/default_purpose/credit_loan_driver.R')
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(tidy = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(fig.width=5, fig.height=4)
measurePrecisionRecall <- function(predict, actual_labels){
precision <- sum(predict & actual_labels) / sum(predict)
recall <- sum(predict & actual_labels) / sum(actual_labels)
fmeasure <- 2 * precision * recall / (precision + recall)
cat('\nPrecision:  ')
cat(round(precision,2))
cat('\n')
cat('Recall (sensitivity):     ')
cat(round(recall,2))
cat('\n')
cat('F-score:  ')
cat(round(fmeasure,2))
cat('\n')
}
df = data.frame(read.csv('GermanData.csv'))
colnames(df) <- c("Status_Checking", "Duration", "Credit_history", "Purpose", "Credit_amount",
"Saving","Empolyment_duration", "Installment_rate", "Personal_status",
"Otherdebtors", "Residence_Year", "Property", "Age", "Other_installment_plan",
"Housing", "Exisiting_credits", "Job", "Liable_People", "Telephone",
"Foreign_worker", "Credit_default")
#write.table(x=df,file = 'german_default.csv', sep = ',', col.names = T)
# Cheking missing values
sort(colSums(is.na(df)),decreasing = T)
df[df$Credit_default==1,'Credit_default'] = 0  # no default
df[df$Credit_default==2,'Credit_default'] = 1  # default
# Feature engineering
# Handling attibute 9
# Attribute 9:  (qualitative)
# 	      Personal status and sex
# 	      A91 : male   : divorced/separated
# 	      A92 : female : divorced/separated/married
#         A93 : male   : single
# 	      A94 : male   : married/widowed
# 	      A95 : female : single
# Creating a specific feature for sex
df[df$Personal_status == 'A91' |  df$Personal_status == 'A94' | df$Personal_status == 'A93' ,'Sex'] = 'M'
df[df$Personal_status == 'A92' |  df$Personal_status == 'A95' , 'Sex'] = 'F'
# Adding meaningful descriptions for Personal_status
df[df$Personal_status == 'A91' | df$Personal_status == 'A92', 'Marital_status'] = 'divorced'
df[df$Personal_status == 'A93' , 'Marital_status'] = 'single'
df[df$Personal_status == 'A94' , 'Marital_status'] = 'married'
df$Personal_status = NULL
df$Sex = as.factor(df$Sex)
df$Marital_status = as.factor(df$Marital_status)
str(df)
#library(dplyr)
#group_by(df[df$Credit_default==1,],Purpose)  %>% summarise(n())
#group_by(df,Personal_status)  %>% summarise(n())
df = data.frame(read.csv('german_default.csv'))
library(caret)
set.seed(7)
library(dummies)
dummies = dummy.data.frame(df, all = FALSE)
Status_checking = c(colnames(dummies[1:4]))
Credit_history = c(colnames(dummies[5:9]))
Purpose = c(colnames(dummies[10:19]))
Savings = c(colnames(dummies[20:24]))
Employment = c(colnames(dummies[25:29]))
Marital_status = c(colnames(dummies[53:55]))
Job = c(colnames(dummies[43:46]))
xName_numeric=c("Duration","Credit_amount","Installment_rate","Age","Exisiting_credits")
xName_categorical=c(Status_checking,Credit_history,Purpose,Savings,Employment,Marital_status,Job)
# Concatening the data
newData = NULL
newData = cbind(dummies[,xName_categorical], df[,xName_numeric], df[,"Credit_default"])
colnames(newData)[42] = 'Credit_default'
# Removing categorical features from the dataset
# newData$Status_Checking = newData$Credit_history = newData$Purpose = newData$Saving = newData$Empolyment_duration =
# newData$Otherdebtors = newData$Property = newData$Other_installment_plan = newData$Housing = newData$Job =newData$Telephone = newData$Foreign_worker = newData$Sex = newData$Marital_status = NULL
# Creating a balanced split for train/test sets : 30% test 70% train
# This will be usefull to compare the logistic model with others
data_part <- createDataPartition(y = newData$Credit_default, p = 0.7, list = F)
X_train = newData[data_part,]
#y_train = df[data_part,c('Credit_default')]
X_test = newData[-data_part,!(colnames(newData) %in% 'Credit_default')]
y_test = newData[-data_part,c('Credit_default')]
# Checking balance
table(y_test)
table(X_train$Credit_default)
# Fiting a logistic model
glm.fit = glm(Credit_default~., data = X_train, family = binomial)
summary(glm.fit)
# Predicting
glm.pred = predict.glm(glm.fit, newdata = X_test, type = "response")
# Calculating accuracy
glm.pred.class = ifelse(glm.pred > 0.5, 1, 0)
mean(y_test == glm.pred.class)
library(pROC)
plot(roc(y_test, glm.pred, direction="<"),col="red", lwd=3, main="ROC curve")
confusionMatrix(data=factor(glm.pred.class, levels = c(1,0)), reference=factor(y_test, levels = c(1,0)))
measurePrecisionRecall(glm.pred.class, y_test)
df = data.frame(read.csv('german_default.csv'))
library(caret)
set.seed(7)
library(dummies)
dummies = dummy.data.frame(df, all = FALSE)
Status_checking = c(colnames(dummies[1:4]))
Credit_history = c(colnames(dummies[5:9]))
Purpose = c(colnames(dummies[10:19]))
Savings = c(colnames(dummies[20:24]))
Employment = c(colnames(dummies[25:29]))
Marital_status = c(colnames(dummies[53:55]))
Job = c(colnames(dummies[43:46]))
xName_numeric=c("Duration","Credit_amount","Installment_rate","Age","Exisiting_credits")
xName_categorical=c(Status_checking,Credit_history,Purpose,Savings,Employment,Marital_status,Job)
# Concatening the data
newData = NULL
newData = cbind(dummies[,xName_categorical], df[,xName_numeric], df[,"Credit_default"])
colnames(newData)[42] = 'Credit_default'
# Removing categorical features from the dataset
# newData$Status_Checking = newData$Credit_history = newData$Purpose = newData$Saving = newData$Empolyment_duration =
# newData$Otherdebtors = newData$Property = newData$Other_installment_plan = newData$Housing = newData$Job =newData$Telephone = newData$Foreign_worker = newData$Sex = newData$Marital_status = NULL
# Creating a balanced split for train/test sets : 30% test 70% train
# This will be usefull to compare the logistic model with others
data_part <- createDataPartition(y = newData$Credit_default, p = 0.7, list = F)
X_train = newData[data_part,]
#y_train = df[data_part,c('Credit_default')]
X_test = newData[-data_part,!(colnames(newData) %in% 'Credit_default')]
y_test = newData[-data_part,c('Credit_default')]
# Checking balance
table(y_test)
table(X_train$Credit_default)
# Fiting a logistic model
glm.fit = glm(Credit_default~., data = X_train, family = binomial)
summary(glm.fit)
# Predicting
glm.pred = predict.glm(glm.fit, newdata = X_test, type = "response")
# Calculating accuracy
glm.pred.class = ifelse(glm.pred > 0.5, 1, 0)
mean(y_test == glm.pred.class)
library(pROC)
plot(roc(y_test, glm.pred, direction="<"),col="red", lwd=3, main="ROC curve for frequentist method")
confusionMatrix(data=factor(glm.pred.class, levels = c(1,0)), reference=factor(y_test, levels = c(1,0)))
measurePrecisionRecall(glm.pred.class, y_test)
library(sigmoid)
# Loading the parameters generated by bayes' logistic
bayesianLogisticParameters = data.frame(read.csv('loan-default-SummaryInfo.csv'))
# Getting the coefficients
intercept = bayesianLogisticParameters[1,'Mean']
coefficients = bayesianLogisticParameters[2:42,'Mean']
# Starting making predictions
predBayes = c()
test = as.matrix(X_test)
for (i in 1:nrow(X_test)){
predBayes[i] = sigmoid(as.numeric(as.vector(X_test[i,])) %*% coefficients + intercept)
}
# Calculating accuracy
bayes.pred.class = ifelse(predBayes > 0.5, 1, 0)
mean(y_test == bayes.pred.class)
length(predBayes)
plot(roc(y_test, predBayes, direction="<"),col="red", lwd=3, main="ROC curve for bayesian method")
confusionMatrix(data=factor(bayes.pred.class, levels = c(1,0)), reference=factor(y_test, levels = c(1,0)))
measurePrecisionRecall(bayes.pred.class, y_test)
source('~/GWU/Bayesian Methods Data Analysis/project/credit_loan_classification/default_job/credit_loan_driver.R')
source('~/GWU/Bayesian Methods Data Analysis/project/credit_loan_classification/default_purpose/credit_loan_driver.R')
source('~/GWU/Bayesian Methods Data Analysis/project/credit_loan_classification/default_job/credit_loan_driver.R')
source('~/GWU/Bayesian Methods Data Analysis/project/credit_loan_classification/default_purpose/credit_loan_driver.R')
