xName_categorical=c(Status_checking,Credit_history,Purpose,Savings,Employment,Marital_status,Job)
# Concatening the data
newData = cbind(df[,xName_numeric], dummies[,xName_categorical])
# Removing categorical features from the dataset
# newData$Status_Checking = newData$Credit_history = newData$Purpose = newData$Saving = newData$Empolyment_duration =
# newData$Otherdebtors = newData$Property = newData$Other_installment_plan = newData$Housing = newData$Job =newData$Telephone = newData$Foreign_worker = newData$Sex = newData$Marital_status = NULL
# Creating a balanced split for train/test sets : 30% test 70% train
# This will be usefull to compare the logistic model with others
data_part <- createDataPartition(y = newData$Credit_default, p = 0.7, list = F)
X_train = newData[data_part,]
#y_train = df[data_part,c('Credit_default')]
X_test = newData[-data_part,!(colnames(newData) %in% 'Credit_default')]
y_test = newData[-data_part,c('Credit_default')]
# Checking balance
table(y_test)
table(X_train$Credit_default)
# Fiting a logistic model
glm.fit = glm(Credit_default~., data = X_train, family = binomial)
summary(glm.fit)
# Predicting
glm.pred = predict.glm(glm.fit, newdata = X_test, type = "response")
# Calculating accuracy
glm.pred.class = ifelse(glm.pred > 0.5, 1, 0)
mean(y_test == glm.pred.class)
library(pROC)
plot(roc(y_test, glm.pred, direction="<"),col="red", lwd=3, main="ROC curve")
confusionMatrix(data=factor(glm.pred.class, levels = c(1,0)), reference=factor(y_test, levels = c(1,0)))
measurePrecisionRecall(glm.pred.class, y_test)
bayesianLogisticParameters[Mean]
bayesianLogisticParameters['Mean']
bayesianLogisticParameters['Mean']
bayesianLogisticParameters[2:42,'Mean']
# Loading the parameters generated by bayes' logistic
bayesianLogisticParameters = data.frame(read.csv('loan-default-SummaryInfo.csv'))
# Getting the coefficients
coefficients = bayesianLogisticParameters[2:42,'Mean']
# Starting making predictions
predBayes = c()
i = 1;
for (X in X_test){
predBayes[i] = sigmoid(X %*% coefficients())
i = i + 1
}
install.packages("sigmoid")
# Loading the parameters generated by bayes' logistic
bayesianLogisticParameters = data.frame(read.csv('loan-default-SummaryInfo.csv'))
# Getting the coefficients
coefficients = bayesianLogisticParameters[2:42,'Mean']
# Starting making predictions
predBayes = c()
i = 1;
for (X in X_test){
predBayes[i] = sigmoid(X %*% coefficients())
i = i + 1
}
bayesianLogisticParameters[1,'Mean']
library(sigmoid)
# Loading the parameters generated by bayes' logistic
bayesianLogisticParameters = data.frame(read.csv('loan-default-SummaryInfo.csv'))
# Getting the coefficients
intercept = bayesianLogisticParameters[1,'Mean']
coefficients = bayesianLogisticParameters[2:42,'Mean']
# Starting making predictions
predBayes = c()
i = 1;
for (X in X_test){
predBayes[i] = sigmoid(X %*% coefficients() + intercept)
i = i + 1
}
library(sigmoid)
# Loading the parameters generated by bayes' logistic
bayesianLogisticParameters = data.frame(read.csv('loan-default-SummaryInfo.csv'))
# Getting the coefficients
intercept = bayesianLogisticParameters[1,'Mean']
coefficients = bayesianLogisticParameters[2:42,'Mean']
# Starting making predictions
predBayes = c()
i = 1;
for (X in X_test){
predBayes[i] = sigmoid(X %*% coefficients + intercept)
i = i + 1
}
library(sigmoid)
# Loading the parameters generated by bayes' logistic
bayesianLogisticParameters = data.frame(read.csv('loan-default-SummaryInfo.csv'))
# Getting the coefficients
intercept = bayesianLogisticParameters[1,'Mean']
coefficients = bayesianLogisticParameters[2:42,'Mean']
# Starting making predictions
predBayes = c()
i = 1;
for (X in X_test){
print(X)
predBayes[i] = sigmoid(X %*% coefficients + intercept)
i = i + 1
}
dim(X_test)
dim(coefficients)
length(coefficients)
length(coefficients)
bayesianLogisticParameters[2:42,'Mean']
length(coefficients)
dim(X_test)
library(sigmoid)
# Loading the parameters generated by bayes' logistic
bayesianLogisticParameters = data.frame(read.csv('loan-default-SummaryInfo.csv'))
# Getting the coefficients
intercept = bayesianLogisticParameters[1,'Mean']
coefficients = bayesianLogisticParameters[2:42,'Mean']
# Starting making predictions
predBayes = c()
i = 1;
for (X in X_test){
print(X)
#predBayes[i] = sigmoid(X %*% coefficients + intercept)
i = i + 1
}
X_test[,1]
X_test[1,]
library(sigmoid)
# Loading the parameters generated by bayes' logistic
bayesianLogisticParameters = data.frame(read.csv('loan-default-SummaryInfo.csv'))
# Getting the coefficients
intercept = bayesianLogisticParameters[1,'Mean']
coefficients = bayesianLogisticParameters[2:42,'Mean']
# Starting making predictions
predBayes = c()
i = 1;
for (X in X_test[i,]){
predBayes[i] = sigmoid(X %*% coefficients + intercept)
i = i + 1
}
predBayes
bayes.pred.class = ifelse(predBayes > 0.5, 1, 0)
mean(y_test == bayes.pred.class)
glm.pred.class = ifelse(glm.pred > 0.5, 1, 0)
mean(y_test == glm.pred.class)
plot(roc(y_test, bayes.pred, direction="<"),col="red", lwd=3, main="ROC curve")
plot(roc(y_test, predBayes, direction="<"),col="red", lwd=3, main="ROC curve")
length(predBayes)
library(sigmoid)
# Loading the parameters generated by bayes' logistic
bayesianLogisticParameters = data.frame(read.csv('loan-default-SummaryInfo.csv'))
# Getting the coefficients
intercept = bayesianLogisticParameters[1,'Mean']
coefficients = bayesianLogisticParameters[2:42,'Mean']
# Starting making predictions
predBayes = c()
for (i in 1:nrow(X_test)){
predBayes[i] = sigmoid(X_test[i,] %*% coefficients + intercept)
}
X_test[1,]
test = as.matrix(X_test)
test
nrow(test)
class(test)
for (i in 1:nrow(test)){
predBayes[i] = sigmoid(test[i,] %*% coefficients + intercept)
}
library(sigmoid)
# Loading the parameters generated by bayes' logistic
bayesianLogisticParameters = data.frame(read.csv('loan-default-SummaryInfo.csv'))
# Getting the coefficients
intercept = bayesianLogisticParameters[1,'Mean']
coefficients = bayesianLogisticParameters[2:42,'Mean']
# Starting making predictions
predBayes = c()
test = as.matrix(X_test)
for (i in 1:nrow(test)){
predBayes[i] = sigmoid(test[i,] %*% coefficients + intercept)
}
# Calculating accuracy
bayes.pred.class = ifelse(predBayes > 0.5, 1, 0)
mean(y_test == bayes.pred.class)
length(predBayes)
plot(roc(y_test, predBayes, direction="<"),col="red", lwd=3, main="ROC curve")
confusionMatrix(data=factor(bayes.pred.class, levels = c(1,0)), reference=factor(y_test, levels = c(1,0)))
measurePrecisionRecall(bayes.pred.class, y_test)
predBayes
print(test[1,])
test
View(test)
test[1,]
test[1,] %*% coefficients
sigmoid(test[1,] %*% coefficients + intercept)
coefficients
test[1,] * coefficients
sigmoid(test[1,] %*% coefficients + intercept)
library(sigmoid)
# Loading the parameters generated by bayes' logistic
bayesianLogisticParameters = data.frame(read.csv('loan-default-SummaryInfo.csv'))
# Getting the coefficients
intercept = bayesianLogisticParameters[1,'Mean']
coefficients = bayesianLogisticParameters[2:42,'Mean']
# Starting making predictions
predBayes = c()
test = as.matrix(X_test)
for (i in 1:nrow(test)){
predBayes[i] = sigmoid(as.numeric(as.vector(X_test[i,])) %*% coefficients + intercept)
}
# Calculating accuracy
bayes.pred.class = ifelse(predBayes > 0.5, 1, 0)
mean(y_test == bayes.pred.class)
length(predBayes)
plot(roc(y_test, predBayes, direction="<"),col="red", lwd=3, main="ROC curve")
confusionMatrix(data=factor(bayes.pred.class, levels = c(1,0)), reference=factor(y_test, levels = c(1,0)))
measurePrecisionRecall(bayes.pred.class, y_test)
as.numeric(as.vector(X_test[1,]))
View(X_test)
as.numeric(as.vector(X_test[1,])) %*% coefficients
as.numeric(as.vector(X_test[1,])) * coefficients
sum(as.numeric(as.vector(X_test[1,])) * coefficients)
coefficients
df = data.frame(read.csv('german_default.csv'))
library(caret)
set.seed(7)
library(dummies)
dummies = dummy.data.frame(df, all = FALSE)
Status_checking = c(colnames(dummies[1:4]))
Credit_history = c(colnames(dummies[5:9]))
Purpose = c(colnames(dummies[10:19]))
Savings = c(colnames(dummies[20:24]))
Employment = c(colnames(dummies[25:29]))
Marital_status = c(colnames(dummies[53:55]))
Job = c(colnames(dummies[43:46]))
xName_numeric=c("Duration","Credit_amount","Installment_rate","Age","Exisiting_credits")
xName_categorical=c(Status_checking,Credit_history,Purpose,Savings,Employment,Marital_status,Job)
# Concatening the data
newData = cbind(dummies[,xName_categorical], df[,xName_numeric], df[,"Credit_default"])
# Removing categorical features from the dataset
# newData$Status_Checking = newData$Credit_history = newData$Purpose = newData$Saving = newData$Empolyment_duration =
# newData$Otherdebtors = newData$Property = newData$Other_installment_plan = newData$Housing = newData$Job =newData$Telephone = newData$Foreign_worker = newData$Sex = newData$Marital_status = NULL
# Creating a balanced split for train/test sets : 30% test 70% train
# This will be usefull to compare the logistic model with others
data_part <- createDataPartition(y = newData$Credit_default, p = 0.7, list = F)
df[,"Credit_default"]
newData = cbind(dummies[,xName_categorical], df[,xName_numeric], df[,"Credit_default"])
View(newData)
View(dummies)
newData = cbind(dummies[,xName_categorical], df[,xName_numeric])
newData = cbind(newData, df[,"Credit_default"])
newData = cbind(dummies[,xName_categorical], df[,xName_numeric])
newData = cbind(newData, df[,'Credit_default'])
newData = cbind(dummies[,xName_categorical], df[,xName_numeric], df[,"Credit_default"])
colnames(newData$`df[, "Credit_default"]`) = 'Credit_default'
newData = NULL
newData = cbind(dummies[,xName_categorical], df[,xName_numeric], df[,"Credit_default"])
colnames(newData$`df[, "Credit_default"]`) = 'Credit_default'
colnames(newData)
colnames(newData)[42] = 'Credit_default'
colnames(newData)[42] = 'Credit_default'
colnames(newData)
df = data.frame(read.csv('german_default.csv'))
library(caret)
set.seed(7)
library(dummies)
dummies = dummy.data.frame(df, all = FALSE)
Status_checking = c(colnames(dummies[1:4]))
Credit_history = c(colnames(dummies[5:9]))
Purpose = c(colnames(dummies[10:19]))
Savings = c(colnames(dummies[20:24]))
Employment = c(colnames(dummies[25:29]))
Marital_status = c(colnames(dummies[53:55]))
Job = c(colnames(dummies[43:46]))
xName_numeric=c("Duration","Credit_amount","Installment_rate","Age","Exisiting_credits")
xName_categorical=c(Status_checking,Credit_history,Purpose,Savings,Employment,Marital_status,Job)
# Concatening the data
newData = NULL
newData = cbind(dummies[,xName_categorical], df[,xName_numeric], df[,"Credit_default"])
colnames(newData)[42] = 'Credit_default'
# Removing categorical features from the dataset
# newData$Status_Checking = newData$Credit_history = newData$Purpose = newData$Saving = newData$Empolyment_duration =
# newData$Otherdebtors = newData$Property = newData$Other_installment_plan = newData$Housing = newData$Job =newData$Telephone = newData$Foreign_worker = newData$Sex = newData$Marital_status = NULL
# Creating a balanced split for train/test sets : 30% test 70% train
# This will be usefull to compare the logistic model with others
data_part <- createDataPartition(y = newData$Credit_default, p = 0.7, list = F)
X_train = newData[data_part,]
#y_train = df[data_part,c('Credit_default')]
X_test = newData[-data_part,!(colnames(newData) %in% 'Credit_default')]
y_test = newData[-data_part,c('Credit_default')]
# Checking balance
table(y_test)
table(X_train$Credit_default)
# Fiting a logistic model
glm.fit = glm(Credit_default~., data = X_train, family = binomial)
summary(glm.fit)
# Predicting
glm.pred = predict.glm(glm.fit, newdata = X_test, type = "response")
# Calculating accuracy
glm.pred.class = ifelse(glm.pred > 0.5, 1, 0)
mean(y_test == glm.pred.class)
library(pROC)
plot(roc(y_test, glm.pred, direction="<"),col="red", lwd=3, main="ROC curve")
confusionMatrix(data=factor(glm.pred.class, levels = c(1,0)), reference=factor(y_test, levels = c(1,0)))
measurePrecisionRecall(glm.pred.class, y_test)
library(sigmoid)
# Loading the parameters generated by bayes' logistic
bayesianLogisticParameters = data.frame(read.csv('loan-default-SummaryInfo.csv'))
# Getting the coefficients
intercept = bayesianLogisticParameters[1,'Mean']
coefficients = bayesianLogisticParameters[2:42,'Mean']
# Starting making predictions
predBayes = c()
test = as.matrix(X_test)
for (i in 1:nrow(X_test)){
predBayes[i] = sigmoid(as.numeric(as.vector(X_test[i,])) %*% coefficients + intercept)
}
# Calculating accuracy
bayes.pred.class = ifelse(predBayes > 0.5, 1, 0)
mean(y_test == bayes.pred.class)
length(predBayes)
plot(roc(y_test, predBayes, direction="<"),col="red", lwd=3, main="ROC curve")
confusionMatrix(data=factor(bayes.pred.class, levels = c(1,0)), reference=factor(y_test, levels = c(1,0)))
measurePrecisionRecall(bayes.pred.class, y_test)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(tidy = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(fig.width=5, fig.height=4)
measurePrecisionRecall <- function(predict, actual_labels){
precision <- sum(predict & actual_labels) / sum(predict)
recall <- sum(predict & actual_labels) / sum(actual_labels)
fmeasure <- 2 * precision * recall / (precision + recall)
cat('\nPrecision:  ')
cat(round(precision,2))
cat('\n')
cat('Recall (sensitivity):     ')
cat(round(recall,2))
cat('\n')
cat('F-score:  ')
cat(round(fmeasure,2))
cat('\n')
}
df = data.frame(read.csv('GermanData.csv'))
colnames(df) <- c("Status_Checking", "Duration", "Credit_history", "Purpose", "Credit_amount",
"Saving","Empolyment_duration", "Installment_rate", "Personal_status",
"Otherdebtors", "Residence_Year", "Property", "Age", "Other_installment_plan",
"Housing", "Exisiting_credits", "Job", "Liable_People", "Telephone",
"Foreign_worker", "Credit_default")
#write.table(x=df,file = 'german_default.csv', sep = ',', col.names = T)
# Cheking missing values
sort(colSums(is.na(df)),decreasing = T)
df[df$Credit_default==1,'Credit_default'] = 0  # no default
df[df$Credit_default==2,'Credit_default'] = 1  # default
# Feature engineering
# Handling attibute 9
# Attribute 9:  (qualitative)
# 	      Personal status and sex
# 	      A91 : male   : divorced/separated
# 	      A92 : female : divorced/separated/married
#         A93 : male   : single
# 	      A94 : male   : married/widowed
# 	      A95 : female : single
# Creating a specific feature for sex
df[df$Personal_status == 'A91' |  df$Personal_status == 'A94' | df$Personal_status == 'A93' ,'Sex'] = 'M'
df[df$Personal_status == 'A92' |  df$Personal_status == 'A95' , 'Sex'] = 'F'
# Adding meaningful descriptions for Personal_status
df[df$Personal_status == 'A91' | df$Personal_status == 'A92', 'Marital_status'] = 'divorced'
df[df$Personal_status == 'A93' , 'Marital_status'] = 'single'
df[df$Personal_status == 'A94' , 'Marital_status'] = 'married'
df$Personal_status = NULL
df$Sex = as.factor(df$Sex)
df$Marital_status = as.factor(df$Marital_status)
str(df)
#library(dplyr)
#group_by(df[df$Credit_default==1,],Purpose)  %>% summarise(n())
#group_by(df,Personal_status)  %>% summarise(n())
#df = data.frame(read.csv('german_default.csv'))
library(caret)
set.seed(7)
library(dummies)
dummies = dummy.data.frame(df, all = FALSE)
Status_checking = c(colnames(dummies[1:4]))
Credit_history = c(colnames(dummies[5:9]))
Purpose = c(colnames(dummies[10:19]))
Savings = c(colnames(dummies[20:24]))
Employment = c(colnames(dummies[25:29]))
Marital_status = c(colnames(dummies[53:55]))
Job = c(colnames(dummies[43:46]))
xName_numeric=c("Duration","Credit_amount","Installment_rate","Age","Exisiting_credits")
xName_categorical=c(Status_checking,Credit_history,Purpose,Savings,Employment,Marital_status,Job)
# Concatening the data
newData = NULL
newData = cbind(dummies[,xName_categorical], df[,xName_numeric], df[,"Credit_default"])
colnames(newData)[42] = 'Credit_default'
# Removing categorical features from the dataset
# newData$Status_Checking = newData$Credit_history = newData$Purpose = newData$Saving = newData$Empolyment_duration =
# newData$Otherdebtors = newData$Property = newData$Other_installment_plan = newData$Housing = newData$Job =newData$Telephone = newData$Foreign_worker = newData$Sex = newData$Marital_status = NULL
# Creating a balanced split for train/test sets : 30% test 70% train
# This will be usefull to compare the logistic model with others
data_part <- createDataPartition(y = newData$Credit_default, p = 0.7, list = F)
X_train = newData[data_part,]
#y_train = df[data_part,c('Credit_default')]
X_test = newData[-data_part,!(colnames(newData) %in% 'Credit_default')]
y_test = newData[-data_part,c('Credit_default')]
# Checking balance
table(y_test)
table(X_train$Credit_default)
# Fiting a logistic model
glm.fit = glm(Credit_default~., data = X_train, family = binomial)
summary(glm.fit)
# Predicting
glm.pred = predict.glm(glm.fit, newdata = X_test, type = "response")
# Calculating accuracy
glm.pred.class = ifelse(glm.pred > 0.5, 1, 0)
mean(y_test == glm.pred.class)
library(pROC)
plot(roc(y_test, glm.pred, direction="<"),col="red", lwd=3, main="ROC curve")
confusionMatrix(data=factor(glm.pred.class, levels = c(1,0)), reference=factor(y_test, levels = c(1,0)))
measurePrecisionRecall(glm.pred.class, y_test)
library(sigmoid)
# Loading the parameters generated by bayes' logistic
bayesianLogisticParameters = data.frame(read.csv('loan-default-SummaryInfo.csv'))
# Getting the coefficients
intercept = bayesianLogisticParameters[1,'Mean']
coefficients = bayesianLogisticParameters[2:42,'Mean']
# Starting making predictions
predBayes = c()
test = as.matrix(X_test)
for (i in 1:nrow(X_test)){
predBayes[i] = sigmoid(as.numeric(as.vector(X_test[i,])) %*% coefficients + intercept)
}
# Calculating accuracy
bayes.pred.class = ifelse(predBayes > 0.5, 1, 0)
mean(y_test == bayes.pred.class)
length(predBayes)
plot(roc(y_test, predBayes, direction="<"),col="red", lwd=3, main="ROC curve")
confusionMatrix(data=factor(bayes.pred.class, levels = c(1,0)), reference=factor(y_test, levels = c(1,0)))
measurePrecisionRecall(bayes.pred.class, y_test)
library(sigmoid)
# Loading the parameters generated by bayes' logistic
bayesianLogisticParameters = data.frame(read.csv('loan-default-SummaryInfo.csv'))
# Getting the coefficients
intercept = bayesianLogisticParameters[1,'Mean']
coefficients = bayesianLogisticParameters[2:42,'Mean']
# Starting making predictions
predBayes = c()
test = as.matrix(X_test)
for (i in 1:nrow(X_test)){
predBayes[i] = sigmoid(as.numeric(as.vector(X_test[i,])) %*% coefficients + intercept)
}
# Calculating accuracy
bayes.pred.class = ifelse(predBayes > 0.5, 1, 0)
mean(y_test == bayes.pred.class)
length(predBayes)
plot(roc(y_test, predBayes, direction="<"),col="red", lwd=3, main="ROC curve")
confusionMatrix(data=factor(bayes.pred.class, levels = c(1,0)), reference=factor(y_test, levels = c(1,0)))
measurePrecisionRecall(bayes.pred.class, y_test)
df = data.frame(read.csv('german_default.csv'))
library(caret)
set.seed(7)
library(dummies)
dummies = dummy.data.frame(df, all = FALSE)
Status_checking = c(colnames(dummies[1:4]))
Credit_history = c(colnames(dummies[5:9]))
Purpose = c(colnames(dummies[10:19]))
Savings = c(colnames(dummies[20:24]))
Employment = c(colnames(dummies[25:29]))
Marital_status = c(colnames(dummies[53:55]))
Job = c(colnames(dummies[43:46]))
xName_numeric=c("Duration","Credit_amount","Installment_rate","Age","Exisiting_credits")
xName_categorical=c(Status_checking,Credit_history,Purpose,Savings,Employment,Marital_status,Job)
# Concatening the data
newData = NULL
newData = cbind(dummies[,xName_categorical], df[,xName_numeric], df[,"Credit_default"])
colnames(newData)[42] = 'Credit_default'
# Removing categorical features from the dataset
# newData$Status_Checking = newData$Credit_history = newData$Purpose = newData$Saving = newData$Empolyment_duration =
# newData$Otherdebtors = newData$Property = newData$Other_installment_plan = newData$Housing = newData$Job =newData$Telephone = newData$Foreign_worker = newData$Sex = newData$Marital_status = NULL
# Creating a balanced split for train/test sets : 30% test 70% train
# This will be usefull to compare the logistic model with others
data_part <- createDataPartition(y = newData$Credit_default, p = 0.7, list = F)
X_train = newData[data_part,]
#y_train = df[data_part,c('Credit_default')]
X_test = newData[-data_part,!(colnames(newData) %in% 'Credit_default')]
y_test = newData[-data_part,c('Credit_default')]
# Checking balance
table(y_test)
table(X_train$Credit_default)
# Fiting a logistic model
glm.fit = glm(Credit_default~., data = X_train, family = binomial)
summary(glm.fit)
# Predicting
glm.pred = predict.glm(glm.fit, newdata = X_test, type = "response")
# Calculating accuracy
glm.pred.class = ifelse(glm.pred > 0.5, 1, 0)
mean(y_test == glm.pred.class)
library(pROC)
plot(roc(y_test, glm.pred, direction="<"),col="red", lwd=3, main="ROC curve")
confusionMatrix(data=factor(glm.pred.class, levels = c(1,0)), reference=factor(y_test, levels = c(1,0)))
measurePrecisionRecall(glm.pred.class, y_test)
library(sigmoid)
# Loading the parameters generated by bayes' logistic
bayesianLogisticParameters = data.frame(read.csv('loan-default-SummaryInfo.csv'))
# Getting the coefficients
intercept = bayesianLogisticParameters[1,'Mean']
coefficients = bayesianLogisticParameters[2:42,'Mean']
# Starting making predictions
predBayes = c()
test = as.matrix(X_test)
for (i in 1:nrow(X_test)){
predBayes[i] = sigmoid(as.numeric(as.vector(X_test[i,])) %*% coefficients + intercept)
}
# Calculating accuracy
bayes.pred.class = ifelse(predBayes > 0.5, 1, 0)
mean(y_test == bayes.pred.class)
length(predBayes)
plot(roc(y_test, predBayes, direction="<"),col="red", lwd=3, main="ROC curve")
confusionMatrix(data=factor(bayes.pred.class, levels = c(1,0)), reference=factor(y_test, levels = c(1,0)))
measurePrecisionRecall(bayes.pred.class, y_test)
source('~/GWU/Bayesian Methods Data Analysis/homework 3/Driver.R')
source('~/GWU/Bayesian Methods Data Analysis/homework 3/Driver.R')
